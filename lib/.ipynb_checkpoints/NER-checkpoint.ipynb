{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c7ad02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-28T21:45:23.558577Z",
     "start_time": "2022-04-28T21:45:18.021759Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizerFast,AutoModel,AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "robertal = \"roberta-large\"\n",
    "bert = \"dslim/bert-base-NER\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(robertal)\n",
    "# model = AutoModelForTokenClassification.from_pretrained(robertal)\n",
    "\n",
    "# nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "# example = \"My name is Wolfgang and I live in Berlin\"\n",
    "\n",
    "# ner_results = nlp(example)\n",
    "# print(ner_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f04da",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc1d709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T01:40:07.983646Z",
     "start_time": "2022-04-29T01:40:07.955886Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/product_ids - feature_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffeb25b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T01:55:54.363858Z",
     "start_time": "2022-04-29T01:55:54.360255Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_location(text, keyword):\n",
    "    start = text.index(keyword)\n",
    "    end = start+len(keyword)\n",
    "    return [start,end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d466c28d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T01:56:53.571479Z",
     "start_time": "2022-04-29T01:56:53.556240Z"
    }
   },
   "outputs": [],
   "source": [
    "df['location']=df.apply(lambda x: extract_location(x['review_text'],x['review_keyword']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d6af903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T01:56:57.685832Z",
     "start_time": "2022-04-29T01:56:57.664916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_id</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_keyword</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>easy to use</td>\n",
       "      <td>4</td>\n",
       "      <td>The Amazon Fire TV Omni is a big deal for Amaz...</td>\n",
       "      <td>easier to use</td>\n",
       "      <td>[95, 108]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>price</td>\n",
       "      <td>4</td>\n",
       "      <td>The Amazon Fire TV Omni is a big deal for Amaz...</td>\n",
       "      <td>a price that's a little more premium</td>\n",
       "      <td>[149, 185]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>performance</td>\n",
       "      <td>4</td>\n",
       "      <td>The Amazon Fire TV Omni is a big deal for Amaz...</td>\n",
       "      <td>disappointing performance</td>\n",
       "      <td>[119, 144]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>resolution</td>\n",
       "      <td>11</td>\n",
       "      <td>The TCL 3 Series S325 is an entry-level 1080p ...</td>\n",
       "      <td>the highest supported resolution of 1080p @ 60Hz</td>\n",
       "      <td>[541, 589]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>resolution</td>\n",
       "      <td>11</td>\n",
       "      <td>The TCL 3 Series S325 is an entry-level 1080p ...</td>\n",
       "      <td>an entry-level 1080p</td>\n",
       "      <td>[25, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>picture quality</td>\n",
       "      <td>11</td>\n",
       "      <td>The TCL 3 Series S325 is an entry-level 1080p ...</td>\n",
       "      <td>mediocre picture quality.</td>\n",
       "      <td>[58, 83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>smart interface</td>\n",
       "      <td>11</td>\n",
       "      <td>The TCL 3 Series S325 is an entry-level 1080p ...</td>\n",
       "      <td>The TV's Roku smart interface is the same as h...</td>\n",
       "      <td>[591, 678]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_id     feature_name  review_id  \\\n",
       "0           1      easy to use          4   \n",
       "1           2            price          4   \n",
       "2           3      performance          4   \n",
       "3           4       resolution         11   \n",
       "4           4       resolution         11   \n",
       "5           5  picture quality         11   \n",
       "6           6  smart interface         11   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  The Amazon Fire TV Omni is a big deal for Amaz...   \n",
       "1  The Amazon Fire TV Omni is a big deal for Amaz...   \n",
       "2  The Amazon Fire TV Omni is a big deal for Amaz...   \n",
       "3  The TCL 3 Series S325 is an entry-level 1080p ...   \n",
       "4  The TCL 3 Series S325 is an entry-level 1080p ...   \n",
       "5  The TCL 3 Series S325 is an entry-level 1080p ...   \n",
       "6  The TCL 3 Series S325 is an entry-level 1080p ...   \n",
       "\n",
       "                                      review_keyword    location  \n",
       "0                                      easier to use   [95, 108]  \n",
       "1               a price that's a little more premium  [149, 185]  \n",
       "2                          disappointing performance  [119, 144]  \n",
       "3   the highest supported resolution of 1080p @ 60Hz  [541, 589]  \n",
       "4                               an entry-level 1080p    [25, 45]  \n",
       "5                          mediocre picture quality.    [58, 83]  \n",
       "6  The TV's Roku smart interface is the same as h...  [591, 678]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc56e7",
   "metadata": {},
   "source": [
    "# Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11938ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T01:43:02.046221Z",
     "start_time": "2022-04-29T01:42:58.431559Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "550c2905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:06:13.177031Z",
     "start_time": "2022-04-29T02:06:10.859096Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(config['model_name'])  # BERT model\n",
    "        self.dropout = nn.Dropout(p=config['dropout'])\n",
    "        self.config = config\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        logits = self.fc1(outputs[0])\n",
    "        logits = self.fc2(self.dropout(logits))\n",
    "        logits = self.fc3(self.dropout(logits)).squeeze(-1)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "config = {\n",
    "    \"max_length\": 416,\n",
    "    \"padding\": \"max_length\",\n",
    "    \"return_offsets_mapping\": True,\n",
    "    \"truncation\": \"only_second\",\n",
    "    \"model_name\": 'bert-base-uncased',#\"roberta-large\",\n",
    "    \"dropout\": 0.2,\n",
    "    \"lr\": 1e-5,\n",
    "    \"test_size\": 0.2,\n",
    "    \"seed\": 1268,\n",
    "    \"batch_size\": 8\n",
    "}\n",
    "\n",
    "model = BertModel(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52a4aa",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5624054d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:01:00.397400Z",
     "start_time": "2022-04-29T02:01:00.385051Z"
    }
   },
   "outputs": [],
   "source": [
    "class NerTrainDataset(Dataset):\n",
    "    def __init__(self, data,tokenizer, config):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_label(self, offset_mapping,location):\n",
    "        labels = np.zeros(len(offset_mapping))\n",
    "        start,end = location\n",
    "        for i,offsets in enumerate(offset_mapping):\n",
    "            s,e = offsets\n",
    "            if s >= start and e <= end:\n",
    "                labels[i]=1\n",
    "        return labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data.loc[idx]\n",
    "        \n",
    "        tokenized = self.tokenizer(\n",
    "            example[\"feature_name\"],\n",
    "            example[\"review_text\"],\n",
    "            truncation = self.config['truncation'],\n",
    "            max_length = self.config['max_length'],\n",
    "            padding = self.config['padding'],\n",
    "            return_offsets_mapping = self.config['return_offsets_mapping']\n",
    "        )\n",
    "        tokenized[\"sequence_ids\"] = tokenized.sequence_ids()\n",
    "        \n",
    "       # print(example['location'])\n",
    "        input_ids = np.array(tokenized[\"input_ids\"])\n",
    "        attention_mask = np.array(tokenized[\"attention_mask\"])\n",
    "        token_type_ids = np.array(tokenized[\"token_type_ids\"])\n",
    "        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n",
    "        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n",
    "        location = example['location']\n",
    "\n",
    "        label = self.get_label(offset_mapping,location)\n",
    "        \n",
    "\n",
    "        return input_ids, attention_mask, token_type_ids, offset_mapping, sequence_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17a5ad56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:01:03.213732Z",
     "start_time": "2022-04-29T02:01:03.210599Z"
    }
   },
   "outputs": [],
   "source": [
    "data = NerTrainDataset(df, tokenizer,config)\n",
    "dataloader = DataLoader(data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c766201",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3626e816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:23:55.450179Z",
     "start_time": "2022-04-29T02:23:55.437468Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "def training(dl,optimizer,epoches = 5,best = 1):\n",
    "    model.train()\n",
    "    losses =[]\n",
    "    for i in tqdm(range(epoches)):\n",
    "        for batch in dl:\n",
    "            input_ids = batch[0]\n",
    "            attention_mask = batch[1]\n",
    "            token_type_ids = batch[2]\n",
    "            offset_mapping = batch[3]\n",
    "            sequence_ids = batch[4]\n",
    "            label = batch[5]\n",
    "            \n",
    "            weight_0 = 1- sum(label[0]==0)/len(label[0])\n",
    "            weight_1 = 1-weight_0\n",
    "            weight = torch.where(label>0,weight_1,weight_0)\n",
    "            \n",
    "            \n",
    "            logits = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits,label,weight = weight)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        train_loss = np.mean(losses)\n",
    "        print('the train loss is:',train_loss)\n",
    "        if train_loss < best:\n",
    "            best = train_loss\n",
    "            torch.save(model.state_dict(),'ner2.pt')\n",
    "        ### END SOLUTION\n",
    "#         valid_loss, valid_acc = valid_metrics(model, valid_dl)\n",
    "#         print(\"train loss  %.3f val loss %.3f and accuracy %.3f\" % (\n",
    "#             train_loss, valid_loss, valid_acc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83a8ade4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:23:57.500801Z",
     "start_time": "2022-04-29T02:23:57.494241Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "wd = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay= wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba060184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:26:20.488476Z",
     "start_time": "2022-04-29T02:24:01.374587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d297d4f2f34d5f8ff56305968f87eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the train loss is: 0.02050299409790427\n",
      "the train loss is: 0.017183706271089078\n",
      "the train loss is: 0.01958349810447427\n",
      "the train loss is: 0.01862410786085852\n",
      "the train loss is: 0.017452359542657433\n"
     ]
    }
   ],
   "source": [
    "training(dataloader,optimizer,epoches = 5,best = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a79df4a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:14:56.339944Z",
     "start_time": "2022-04-29T02:14:56.321846Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43a659c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:27:30.456857Z",
     "start_time": "2022-04-29T02:27:30.083296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('ner2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "140c6e7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:27:31.355272Z",
     "start_time": "2022-04-29T02:27:31.351713Z"
    }
   },
   "outputs": [],
   "source": [
    "# batch = next(iter(dataloader))\n",
    "input_ids = batch[0]\n",
    "attention_mask = batch[1]\n",
    "token_type_ids = batch[2]\n",
    "offset_mapping = batch[3]\n",
    "sequence_ids = batch[4]\n",
    "label = batch[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1cfd3676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:27:33.683665Z",
     "start_time": "2022-04-29T02:27:32.372080Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits = model(input_ids, attention_mask, token_type_ids)\n",
    "predicted = logits.detach().cpu().numpy()\n",
    "offset_mapping = offset_mapping.numpy()\n",
    "sequence_ids = sequence_ids.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "12218024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-29T02:27:51.278145Z",
     "start_time": "2022-04-29T02:27:51.266380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current index 27 202\n",
      "Word:   is a very basic, entry-level 4k TV. Along with the Fire TV Omni, it's one of the first Amazon-branded TVs. It's best-suited for a dark room, as the VA panel delivers deep bla\n",
      "Current index 204 236\n",
      "Word:  s but can't get bright enough to\n"
     ]
    }
   ],
   "source": [
    "for pred, offsets, seq_ids in zip(predicted, offset_mapping, sequence_ids):\n",
    "    pred = 1 / (1 + np.exp(-pred)) # which is sigmoid function    \n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "    \n",
    "    for pred, offset, seq_id in zip(pred, offsets, seq_ids):\n",
    "        if not seq_id or seq_id == 0:\n",
    "            continue\n",
    "    \n",
    "        if pred > 0.5:\n",
    "            if not start_idx:\n",
    "                start_idx = offset[0]\n",
    "            end_idx = offset[1]\n",
    "            \n",
    "        elif start_idx:\n",
    "            print(\"Current index\", f\"{start_idx} {end_idx}\")\n",
    "            print(\"Word: \", text[start_idx:end_idx])\n",
    "            start_idx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513bc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
